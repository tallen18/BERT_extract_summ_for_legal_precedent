{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Steps for Aggregation Analysis\n",
        "\n",
        "### 1. Load the data\n",
        ">* Need to lead the data from the Aggregation Preprocessor File. It includes the original sentence scores, the positionally updated sentence scores, and the batch model updated sentence scores.\n",
        "\n",
        "### 2. Run the Golden Comparison Score Anlysis\n",
        ">* For each calculated score, compare the scores of golden sentences to the scores of non-golden sentences\n",
        "\n",
        "### 3. Run the top-k and top-2k analysis\n",
        ">* Calculate the top k and 2*k scores for each document (where k is the number of golden sentences in that document).\n",
        ">* See how what percentage of k and 2*k sentences are actually golden sentences\n",
        "\n",
        "### 4. Create a plot that dives deeper into where golden sentences are located when ordered after aggregation"
      ],
      "metadata": {
        "id": "kHMLfLShOTD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Data"
      ],
      "metadata": {
        "id": "pHaRKAEdPW3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "mwsR5_BOyneI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ATl6deyG7xKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scored_df = pd.read_pickle('/content/gdrive/MyDrive/Thesis/Data/scored_df.pickle')"
      ],
      "metadata": {
        "id": "DOcPFf7i7nZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Golden Comparison Score"
      ],
      "metadata": {
        "id": "R9Yd-Ddw6elc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn0JOjM3DSNn"
      },
      "outputs": [],
      "source": [
        "def gold_vs_avg(is_summ, pred_outcome):\n",
        "\n",
        "  #Flatten both lists\n",
        "  #flat_sums = [item for sublist in is_summ for item in sublist]\n",
        "\n",
        "  #Creating lineary array of just 0s and 1s based on each sentence being in the summary\n",
        "  flat_sums = []\n",
        "  for i in is_summ:\n",
        "    for j in i:\n",
        "      for k in j:\n",
        "        flat_sums.append(k)\n",
        "  \n",
        "  #print(flat_sums)\n",
        "\n",
        "  #flat_preds = [item for sublist in pred_outcome for item in sublist]\n",
        "  flat_preds = []\n",
        "  for i in pred_outcome:\n",
        "    for j in i:\n",
        "      for k in j:\n",
        "        if isinstance(k,list):\n",
        "          flat_preds.append(k[0])\n",
        "        else:\n",
        "          flat_preds.append(k)\n",
        "\n",
        "  print(len(flat_sums))\n",
        "  print(len(flat_preds))\n",
        "\n",
        "  golden_scores = []\n",
        "  normal_scores = []\n",
        "\n",
        "  for i in range(len(flat_sums)):\n",
        "    if flat_sums[i] == 0:\n",
        "       normal_scores.append(flat_preds[i])\n",
        "    else:\n",
        "      golden_scores.append(flat_preds[i])\n",
        "  \n",
        "  print('Average Score for Golden Sentences:', sum(golden_scores) / len(golden_scores))\n",
        "  print('Average Score for Normal Sentences:', sum(normal_scores) / len(normal_scores))\n",
        "\n",
        "  print('Golden Comparison Score:',  (sum(golden_scores) / len(golden_scores)) / (sum(normal_scores) / len(normal_scores)))\n",
        "\n",
        "  print('Total Number of Golden Sentences:', len(golden_scores))\n",
        "  print('Total Number of Normal Sentences:', len(normal_scores))\n",
        "\n",
        "  fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "  # Create a histogram for the first list\n",
        "  axs[0].hist(golden_scores, bins=10, color='blue', alpha=0.5)\n",
        "  axs[0].set_title('Golden Sentences')\n",
        "\n",
        "  # Create a histogram for the second list\n",
        "  axs[1].hist(normal_scores, bins=10, color='green', alpha=0.5)\n",
        "  axs[1].set_title('Normal Sentences')\n",
        "\n",
        "  # Add axis labels and a title for the plot\n",
        "  #fig.suptitle('Histograms of two lists')\n",
        "  axs[0].set_xlabel('Values')\n",
        "  axs[0].set_ylabel('Frequency')\n",
        "  axs[1].set_xlabel('Values')\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()\n",
        "\n",
        "  return golden_scores, normal_scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_summ = scored_df['batch_labels']\n",
        "\n",
        "pred_outcome1 = scored_df['pred_outcomes']\n",
        "print('Results for Linear ------->')\n",
        "lin_g_scores, lin_n_scores = gold_vs_avg(is_summ, pred_outcome1)\n",
        "\n",
        "pred_outcome2 = scored_df['pos_update']\n",
        "print('Results for Positional ------->')\n",
        "pos_g_scores, pos_n_scores = gold_vs_avg(is_summ, pred_outcome2)\n",
        "\n",
        "pred_outcome3 = scored_df['bin_class_update']\n",
        "print('Results for Batch Binary Classification ------->')\n",
        "class_g_scores, class_n_scores = gold_vs_avg(is_summ, pred_outcome3)"
      ],
      "metadata": {
        "id": "MR5VaZ5d7jP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top-K and Top-2K"
      ],
      "metadata": {
        "id": "m1DM16TOAh0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k(sent_in_sum, pred_scores, k):\n",
        "  '''\n",
        "  This code looks at one case at a time.\n",
        "  It flattens both lists of scores and in_summs, orders both lists by the pred_scores max, chooses top k scores, sees if they are in the final summary\n",
        "  It returns the percentage of top k sentences that are actually summaries\n",
        "  '''\n",
        "\n",
        "  #Flatten the first list labels for the sentences within a case:\n",
        "  case_sent_labels = []\n",
        "  for i in sent_in_sum:\n",
        "    for j in i:\n",
        "      case_sent_labels.append(j)\n",
        "\n",
        "  #Flatten the second list of the predicted scores for each sentennce:\n",
        "  case_pred_scores = []\n",
        "  for i in pred_scores:\n",
        "    for j in i:\n",
        "      if isinstance(j,list):\n",
        "          case_pred_scores.append(j[0])\n",
        "      else:\n",
        "          case_pred_scores.append(j)\n",
        "\n",
        "  #Check they are the same length\n",
        "  # print(len(case_sent_labels))\n",
        "  # print(len(case_pred_scores))\n",
        "\n",
        "  #Order both lists from highest to lowest of predcitced scores\n",
        "  combined = list(zip(case_pred_scores, case_sent_labels)) #Zipping lists to together to make list of tuples based on indcies\n",
        "  sorted_tuples = sorted(combined, reverse=True) #Sorting based on the first item in the tuple\n",
        "\n",
        "  #Choose the top-k from the list of tuples\n",
        "  top_sentences = sorted_tuples[:k]\n",
        "\n",
        "  #Calcualte Percent of top sentences that are golden\n",
        "  num_golden = 0\n",
        "  for sent in top_sentences:\n",
        "    if sent[1] == 1:\n",
        "      num_golden += 1\n",
        "  \n",
        "  percent_golden = num_golden / k\n",
        "\n",
        "  return percent_golden, k\n",
        "\n"
      ],
      "metadata": {
        "id": "cXQqdWGoAi5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "case_data = scored_df['case_text']\n",
        "all_batch_labels = scored_df['batch_labels']\n",
        "linear_preds = scored_df['pred_outcomes']\n",
        "pos_preds = scored_df['pos_update']\n",
        "batch_model_preds = scored_df['bin_class_update']\n",
        "all_summaries = scored_df['summaries']"
      ],
      "metadata": {
        "id": "RS73lCFQF4JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_by_k(topk_percent, k_list, title = 'Average Score as Function of K'):\n",
        "  '''\n",
        "  Helper function to plot the k values\n",
        "  '''\n",
        "  #Make a dictionary holding the values\n",
        "  holder = {}\n",
        "  for i in range(len(k_list)):\n",
        "    k = k_list[i]\n",
        "    percent = topk_percent[i]\n",
        "\n",
        "    if k not in holder:\n",
        "      holder[k] = [percent]\n",
        "    \n",
        "    else:\n",
        "      holder[k].append(percent)\n",
        "\n",
        "  #Plot the average of the values as function of keys\n",
        "  averages = {key: round(100 * (sum(values) / len(values)), 2) for key, values in holder.items()}\n",
        "\n",
        "  # Create a bar chart of the averages\n",
        "  plt.bar(averages.keys(), averages.values())\n",
        "\n",
        "  # Set the title and axis labels\n",
        "  plt.title(title)\n",
        "  plt.xlabel('K')\n",
        "  plt.ylabel('% of Top K Sentences that are Golden')\n",
        "\n",
        "  # Display the plot\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Ksnwx9dvwIr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Start with Linear Analysis\n",
        "\n",
        "linear_topk_percent = [] #Stores the percentage of top-k sentences that are golden for each case\n",
        "linear_top2k_percent = []\n",
        "linear_k = [] #Stores the k number for each case\n",
        "linear_2k = []\n",
        "\n",
        "for i in range(len(case_data)):\n",
        "\n",
        "  k = len(all_summaries[i])\n",
        "\n",
        "  case_scores = linear_preds[i]\n",
        "  case_labels = all_batch_labels[i]\n",
        "\n",
        "  percent_golden, k = top_k(case_labels, case_scores, k)\n",
        "\n",
        "  two_linear_percent_golden, two_k = top_k(case_labels, case_scores, 2*k)\n",
        "\n",
        "  linear_topk_percent.append(percent_golden)\n",
        "  linear_k.append(k)\n",
        "  linear_top2k_percent.append(two_linear_percent_golden)\n",
        "  linear_2k.append(two_k)\n",
        "\n",
        "plot_by_k(linear_topk_percent, linear_k, 'Linear Aggregation')\n",
        "plot_by_k(linear_top2k_percent, linear_2k)\n",
        "\n",
        "print('Linear Results --->')\n",
        "print('Average Percent of top-k sentences:', sum(linear_topk_percent) / len(linear_topk_percent))\n",
        "print('Average Percent of top-2k sentences:', sum(linear_top2k_percent) / len(linear_top2k_percent))"
      ],
      "metadata": {
        "id": "JQPplJhWIWYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Next we do Positional Results\n",
        "\n",
        "pos_topk_percent = [] #Stores the percentage of top-k sentences that are golden for each case\n",
        "pos_top2k_percent = []\n",
        "pos_k = [] #Stores the k number for each case\n",
        "pos_2k = []\n",
        "\n",
        "for i in range(len(case_data)):\n",
        "\n",
        "  k = len(all_summaries[i])\n",
        "\n",
        "  case_scores = pos_preds[i]\n",
        "  case_labels = all_batch_labels[i]\n",
        "\n",
        "  percent_golden, k = top_k(case_labels, case_scores, k)\n",
        "\n",
        "  two_pos_percent_golden, two_k = top_k(case_labels, case_scores, k*2)\n",
        "\n",
        "  pos_topk_percent.append(percent_golden)\n",
        "  pos_k.append(k)\n",
        "  pos_top2k_percent.append(two_pos_percent_golden)\n",
        "  pos_2k.append(two_k)\n",
        "\n",
        "plot_by_k(pos_topk_percent, pos_k, 'Poistional Aggregation')\n",
        "plot_by_k(pos_top2k_percent, pos_2k)\n",
        "\n",
        "print('Positional Results --->')\n",
        "print('Average Percent of top-k sentences:', sum(pos_topk_percent) / len(pos_topk_percent))\n",
        "print('Average Percent of top-2k sentences:', sum(pos_top2k_percent) / len(pos_top2k_percent))"
      ],
      "metadata": {
        "id": "jWPwYMgGKK8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Next we do Model Results\n",
        "\n",
        "model_topk_percent = [] #Stores the percentage of top-k sentences that are golden for each case\n",
        "model_top2k_percent = []\n",
        "model_k = [] #Stores the k number for each case\n",
        "model_2k = []\n",
        "\n",
        "for i in range(len(case_data)):\n",
        "\n",
        "  k = len(all_summaries[i])\n",
        "\n",
        "  case_scores = batch_model_preds[i]\n",
        "  case_labels = all_batch_labels[i]\n",
        "\n",
        "  percent_golden, k = top_k(case_labels, case_scores, k)\n",
        "\n",
        "  two_model_percent_golden, two_k = top_k(case_labels, case_scores, k*2)\n",
        "\n",
        "  model_topk_percent.append(percent_golden)\n",
        "  model_k.append(k)\n",
        "  model_top2k_percent.append(two_model_percent_golden)\n",
        "  model_2k.append(two_k)\n",
        "\n",
        "plot_by_k(model_topk_percent, pos_k, title = 'Model Aggreagation')\n",
        "plot_by_k(model_top2k_percent, pos_2k)\n",
        "\n",
        "print('Model Results --->')\n",
        "print('Average Percent of top-k sentences:', sum(model_topk_percent) / len(model_topk_percent))\n",
        "print('Average Percent of top-2k sentences:', sum(model_top2k_percent) / len(model_top2k_percent))"
      ],
      "metadata": {
        "id": "Hbh20pKJNS9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a plot that dives deeper into where golden sentences are located when ordered after aggregation"
      ],
      "metadata": {
        "id": "Qm_y0QwqAPX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def exp(sent_in_sum, pred_scores):\n",
        "  '''\n",
        "  This code looks at one case at a time.\n",
        "  It flattens both lists of scores and in_summs, orders both lists by the pred_scores max, chooses top k scores, sees if they are in the final summary\n",
        "  It returns the percentage of top k sentences that are actually summaries\n",
        "  '''\n",
        "\n",
        "  #Flatten the first list labels for the sentences within a case:\n",
        "  case_sent_labels = []\n",
        "  for i in sent_in_sum:\n",
        "    for j in i:\n",
        "      case_sent_labels.append(j)\n",
        "\n",
        "  #Flatten the second list of the predicted scores for each sentennce:\n",
        "  case_pred_scores = []\n",
        "  for i in pred_scores:\n",
        "    for j in i:\n",
        "      if isinstance(j,list):\n",
        "          case_pred_scores.append(j[0])\n",
        "      else:\n",
        "          case_pred_scores.append(j)\n",
        "\n",
        "  #Order both lists from highest to lowest of predcitced scores\n",
        "  combined = list(zip(case_pred_scores, case_sent_labels)) #Zipping lists to together to make list of tuples based on indcies\n",
        "  sorted_tuples = sorted(combined, reverse=True) #Sorting based on the first item in the tuple\n",
        "\n",
        "  #Expirimenting\n",
        "  list1 = [x[0] for x in sorted_tuples]\n",
        "  list2 = [x[1] for x in sorted_tuples]\n",
        "\n",
        "  return list2"
      ],
      "metadata": {
        "id": "GOoBnvGOAREH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "for i in range(len(case_data)):\n",
        "\n",
        "  case_scores = batch_model_preds[i]\n",
        "  case_labels = all_batch_labels[i]\n",
        "\n",
        "  list_of_yeses = exp(case_labels, case_scores)\n",
        "\n",
        "  result.append(list_of_yeses)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a list of lists with different lengths\n",
        "\n",
        "# Find the maximum length of any internal list\n",
        "max_length = max(len(l) for l in result)\n",
        "\n",
        "# Pad each internal list with zeros so they all have the same length\n",
        "padded_list = [l + [0] * (max_length - len(l)) for l in result]\n",
        "\n",
        "# Convert the list of lists to a two-dimensional numpy array\n",
        "arr = np.array(padded_list)\n",
        "\n",
        "# Compute the histogram of where the 1s occur in each column\n",
        "hist = np.sum(arr == 1, axis=0)\n",
        "\n",
        "# Truncate the histogram if it has more than 200 bins\n",
        "if len(hist) > 100:\n",
        "    hist = hist[:100]\n",
        "    \n",
        "# Plot the histogram\n",
        "plt.bar(range(len(hist)), hist)\n",
        "plt.xlim(0, len(hist)-1)\n",
        "plt.xticks(range(0, len(hist), 20))\n",
        "plt.title('Weighted by Batch Model')\n",
        "plt.xlabel('Position from Ordered Scores')\n",
        "plt.ylabel('Number of Golden Sentences')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hWXD7CgNAcIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "for i in range(len(case_data)):\n",
        "\n",
        "  case_scores = pos_preds[i]\n",
        "  case_labels = all_batch_labels[i]\n",
        "\n",
        "  list_of_yeses = exp(case_labels, case_scores)\n",
        "\n",
        "  result.append(list_of_yeses)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a list of lists with different lengths\n",
        "\n",
        "# Find the maximum length of any internal list\n",
        "max_length = max(len(l) for l in result)\n",
        "\n",
        "# Pad each internal list with zeros so they all have the same length\n",
        "padded_list = [l + [0] * (max_length - len(l)) for l in result]\n",
        "\n",
        "# Convert the list of lists to a two-dimensional numpy array\n",
        "arr = np.array(padded_list)\n",
        "\n",
        "# Compute the histogram of where the 1s occur in each column\n",
        "hist = np.sum(arr == 1, axis=0)\n",
        "\n",
        "# Truncate the histogram if it has more than 200 bins\n",
        "if len(hist) > 100:\n",
        "    hist = hist[:100]\n",
        "    \n",
        "# Plot the histogram\n",
        "plt.bar(range(len(hist)), hist)\n",
        "plt.xlim(0, len(hist)-1)\n",
        "plt.title('Weighted by Position')\n",
        "plt.xticks(range(0, len(hist), 20))\n",
        "plt.xlabel('Position from Ordered Scores')\n",
        "plt.ylabel('Number of Golden Sentences')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dJ169HyJCghM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "for i in range(len(case_data)):\n",
        "\n",
        "  case_scores = linear_preds[i]\n",
        "  case_labels = all_batch_labels[i]\n",
        "\n",
        "  list_of_yeses = exp(case_labels, case_scores)\n",
        "\n",
        "  result.append(list_of_yeses)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a list of lists with different lengths\n",
        "\n",
        "# Find the maximum length of any internal list\n",
        "max_length = max(len(l) for l in result)\n",
        "\n",
        "# Pad each internal list with zeros so they all have the same length\n",
        "padded_list = [l + [0] * (max_length - len(l)) for l in result]\n",
        "\n",
        "# Convert the list of lists to a two-dimensional numpy array\n",
        "arr = np.array(padded_list)\n",
        "\n",
        "# Compute the histogram of where the 1s occur in each column\n",
        "hist = np.sum(arr == 1, axis=0)\n",
        "\n",
        "# Truncate the histogram if it has more than 200 bins\n",
        "if len(hist) > 100:\n",
        "    hist = hist[:100]\n",
        "    \n",
        "# Plot the histogram\n",
        "plt.bar(range(len(hist)), hist)\n",
        "plt.xlim(0, len(hist)-1)\n",
        "plt.title('Linear Ordering')\n",
        "plt.xticks(range(0, len(hist), 20))\n",
        "plt.xlabel('Position from Ordered Scores')\n",
        "plt.ylabel('Number of Golden Sentences')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X_irKNiYDyDK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}